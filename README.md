SPEECH-RECOGNITION-SYSTEM

COMPANY: CODTECH IT SOLUTIONS

NAME: T SAI PAVAN

INTERN ID: CT04DF2913

DOMAIN: ARTIFICIAL INTELLIGENCE

DURATION: 4 WEEEKS

MENTOR: NEELA SANTOSH

DESCRIPTION: As part of my internship at CODTECH, I developed a real-time Speech Recognition System using Python and Natural Language Processing (NLP) techniques. The primary objective of this project was to create a tool capable of converting spoken language into written text with high accuracy, enabling hands-free interaction with digital systems. This technology has significant applications in voice-controlled assistants, accessibility tools for differently-abled users, automated transcription services, and interactive voice response (IVR) systems, making it invaluable across industries like healthcare, customer service, and smart device development.

To build this system, I utilized Python due to its extensive AI/ML ecosystem and the speech_recognition library, which provides seamless integration with multiple speech recognition APIs. The tool works by capturing audio input through the system’s microphone, processing it to filter background noise, and transcribing it into text using Google’s Web Speech API, known for its robust performance in real-time applications. The implementation involves initializing a Recognizer object to handle audio processing and a Microphone object to record user speech. Before transcription, the system performs ambient noise adjustment to enhance accuracy, particularly in noisy environments. The recorded audio is then sent to Google’s cloud-based API, which returns the transcribed text. Error handling mechanisms are included to manage cases where speech is unclear or network issues disrupt the API connection.

For development, I used Visual Studio Code (VS Code), leveraging its powerful features like IntelliSense, debugging, and terminal integration to streamline the coding process. The system is designed for easy integration into larger projects, such as voice assistants or automated captioning tools, and can be extended with additional functionalities like wake-word detection or offline recognition using alternative APIs like CMU Sphinx.

This project significantly enhanced my understanding of audio processing, NLP, and API integration, while also improving my problem-solving skills in handling real-world challenges like noise interference and connectivity issues. The experience reinforced my proficiency in Python and modern AI frameworks, preparing me for more advanced applications in speech and language technologies. Future enhancements could include multilingual support, custom wake-word activation, or integration with generative AI models like ChatGPT for voice-based conversational agents.

Overall, this task provided hands-on experience in developing an end-to-end speech recognition solution, demonstrating the practical applications of NLP in automating and enhancing human-computer interactions. The skills gained align perfectly with CODTECH’s focus on innovative AI-driven solutions, and I look forward to applying this knowledge to more complex projects in the future.

OUTPUT:
![image](https://github.com/user-attachments/assets/96ced595-ec04-4e27-95fc-553a423bb978)
